# ======================
# IMPORTACI√ìN DE LIBRER√çAS
# ======================
import streamlit as st
import pandas as pd
import numpy as np
from faker import Faker
import random
from datetime import datetime, timedelta
from sklearn.feature_extraction.text import TfidfVectorizer
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ======================
# CONFIGURACI√ìN INICIAL
# ======================
st.set_page_config(
    page_title="Sophivigil Dashboard",
    layout="wide",
    page_icon="üëÅÔ∏è",
    initial_sidebar_state="expanded"
)

# ======================
# FUNCIONES AUXILIARES
# ======================
@st.cache_resource(show_spinner=False)
def get_faker_instance():
    return Faker('es_MX')

def create_demographics(fake):
    dob = fake.date_of_birth(minimum_age=20, maximum_age=80)
    genero = random.choice(["M", "F"])
    nombre = fake.first_name()
    apellido = fake.last_name()
    
    # Generate initials safely
    parts = [p.strip() for p in nombre.split() if p.strip()]
    
    if len(parts) >= 2:
        # Handle potential single-character parts
        first_char = parts[0][0] if parts[0] else ''
        second_char = parts[1][0] if len(parts[1]) > 0 else ''
        iniciales = f"{first_char}{second_char}{apellido[0]}"
    else:
        # Fallback to first char of first name + last name
        iniciales = f"{nombre[0]}{apellido[0]}" if nombre and apellido else "XX"
    
    return dob, genero, iniciales

def create_treatment_data(fake, hoy):
    start_treatment = fake.date_this_year(before_today=True, after_today=False)
    continues_treatment = random.choice([True, False])
    end_treatment = fake.date_between(start_date=start_treatment, end_date=hoy) if not continues_treatment else None
    return start_treatment, continues_treatment, end_treatment

def create_reaction_data(fake, start_treatment, hoy):
    prob_antes_tratamiento = 0.3
    if random.random() < prob_antes_tratamiento:
        fecha_min = start_treatment - timedelta(days=30)
        fecha_max = start_treatment
    else:
        fecha_min = start_treatment
        fecha_max = min(start_treatment + timedelta(days=90), hoy)
    
    onset = fake.date_between_dates(date_start=fecha_min, date_end=fecha_max)
    reaccion_continua = random.choice([True, False])
    end_reaction = fake.date_between_dates(date_start=onset, date_end=hoy) if not reaccion_continua else None
    return onset, reaccion_continua, end_reaction

def create_description(fake):
    sintomas = ["enrojecimiento", "picaz√≥n", "visi√≥n borrosa", "dolor ocular", 
               "sequedad", "sensibilidad a la luz", "inflamaci√≥n", "lagrimeo"]
    descripcion = f"Paciente reporta {random.choice(sintomas)}"
    if random.random() > 0.5:
        descripcion += f" acompa√±ado de {random.choice(sintomas)}"
    descripcion += f". {fake.sentence()}"
    return descripcion

@st.cache_data(show_spinner="Generando datos sint√©ticos...")
def generate_adr_data(num_records=15):
    # Validate minimum records
    if num_records < 5:
        num_records = 5
        st.warning("N√∫mero m√≠nimo de registros ajustado a 5 para an√°lisis significativo")
    
    fake = get_faker_instance()
    productos = [
        "3-A Ofteno", "Acquafil Ofteno", "Deltamid", "Dustalox", "Eliptic Ofteno",
        "Gaap Ofteno", "Humylub Ofteno", "Krytantek Ofteno", "Lagricel Ofteno",
        "Manzanilla Sophia", "Meticel Ofteno", "Nazil", "Sopix√≠n DX", "Trazidex"
    ]
    
    relaciones = ["Paciente", "Familiar", "Profesional de salud"]
    severidades = ["Leve", "Moderado", "Grave"]
    data = []
    hoy = datetime.now().date()
    
    for _ in range(num_records):
        # Datos demogr√°ficos con validaci√≥n
        dob, genero, iniciales = create_demographics(fake)
        
        # Tratamiento
        start_treatment, continues_treatment, end_treatment = create_treatment_data(fake, hoy)
        
        # Reacci√≥n adversa
        onset, reaccion_continua, end_reaction = create_reaction_data(fake, start_treatment, hoy)
        
        # Descripci√≥n
        descripcion = create_description(fake)
        
        # C√°lculo de duraciones con validaci√≥n de fechas
        try:
            duracion_tratamiento = (end_treatment - start_treatment).days if end_treatment else (hoy - start_treatment).days
            duracion_reaccion = (end_reaction - onset).days if end_reaction else (hoy - onset).days
        except TypeError:
            # Fallback if date calculation fails
            duracion_tratamiento = random.randint(30, 365)
            duracion_reaccion = random.randint(1, 90)

        record = {
            "ID": fake.unique.bothify(text='RPT-#####'),
            "Iniciales": iniciales,
            "Edad": hoy.year - dob.year,
            "G√©nero": genero,
            "Pa√≠s": fake.country_code(representation="alpha-2"),
            "Producto": random.choice(productos),
            "Inicio_Tratamiento": start_treatment,
            "Duraci√≥n_Tratamiento": duracion_tratamiento,
            "Contin√∫a": "Si" if continues_treatment else "No",
            "Fin_Tratamiento": end_treatment,
            "Lote": fake.bothify(text='LOT-??###'),
            "Evento_Adverso": fake.sentence(nb_words=4),
            "Inicio_Reacci√≥n": onset,
            "D√≠as_Inicio_Reacci√≥n": (onset - start_treatment).days,
            "Fin_Reacci√≥n": end_reaction,
            "Duraci√≥n_Reacci√≥n": duracion_reaccion,
            "Descripci√≥n": descripcion,
            "Reportero": fake.name(),
            "Relaci√≥n": random.choice(relaciones),
            "Severidad_Reportada": random.choice(severidades),
            "Tel√©fono": fake.phone_number(),
            "Email": fake.email(),
            "Fecha_Reporte": fake.date_between(start_date=onset, end_date=hoy)
        }
        data.append(record)
    
    df = pd.DataFrame(data)
    
    # Convertir a formato datetime con manejo de errores
    date_cols = ["Inicio_Tratamiento", "Fin_Tratamiento", "Inicio_Reacci√≥n", 
                "Fin_Reacci√≥n", "Fecha_Reporte"]
    for col in date_cols:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
            # Fill missing dates with reasonable values
            if df[col].isnull().any():
                df[col] = df[col].fillna(pd.Timestamp(datetime.now().date()))
    
    return df

def apply_filters(df, all_products, productos_filtro, severidad_filtro, fecha_filtro):
    filtered_df = df.copy()
    
    if not all_products and productos_filtro:
        filtered_df = filtered_df[filtered_df["Producto"].isin(productos_filtro)]
        
    if severidad_filtro:
        filtered_df = filtered_df[filtered_df["Predicci√≥n"].isin(severidad_filtro)]
    
    if fecha_filtro:
        filtered_df = filtered_df[filtered_df["Fecha_Reporte"] >= pd.to_datetime(fecha_filtro)]
    
    return filtered_df

def generate_predictions(df):
    np.random.seed(42)
    pred_labels = np.random.choice(["Leve", "Moderado", "Grave"], size=len(df), p=[0.5, 0.3, 0.2])
    df["Predicci√≥n"] = pred_labels
    
    probabilidades = np.random.dirichlet([1, 1, 1], size=len(df))
    df["Confianza"] = [f"{p.max()*100:.1f}%" for p in probabilidades]
    
    return df

# ======================
# FUNCIONES DE VISUALIZACI√ìN
# ======================
def render_kpi_section(df, filtered_df):
    graves = filtered_df[filtered_df["Predicci√≥n"] == "Grave"]
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Reportes", len(filtered_df), delta=f"{len(filtered_df)-len(df)} desde √∫ltima actualizaci√≥n")
    with col2:
        st.metric("Casos Graves", len(graves), delta_color="inverse")
    with col3:
        productos_count = filtered_df["Producto"].nunique()
        st.metric("Productos Reportados", productos_count)
    with col4:
        avg_response = filtered_df["D√≠as_Inicio_Reacci√≥n"].mean() if not filtered_df.empty else 0
        st.metric("Tiempo Reacci√≥n Promedio", f"{avg_response:.1f} d√≠as")
    
    if not graves.empty:
        st.error(f"üö® **ALERTA:** Se detectaron {len(graves)} casos graves que requieren atenci√≥n inmediata!")
        with st.expander("Ver detalles de casos graves"):
            st.dataframe(graves[["ID", "Producto", "Evento_Adverso", "Inicio_Reacci√≥n", "Descripci√≥n", "Confianza"]])
    
    st.markdown("---")

def render_distribution_tab(filtered_df):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Severidad de Eventos")
        if not filtered_df.empty:
            fig = px.pie(
                filtered_df, 
                names="Predicci√≥n", 
                color="Predicci√≥n",
                color_discrete_map={"Leve":"#2ecc71", "Moderado":"#f39c12", "Grave":"#e74c3c"}
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("No hay datos para mostrar")
    
    with col2:
        st.subheader("Top Productos Reportados")
        if not filtered_df.empty:
            top_products = filtered_df["Producto"].value_counts().nlargest(5).reset_index()
            top_products.columns = ['Producto', 'Reportes']
            
            fig = px.bar(
                top_products, 
                x='Reportes',
                y='Producto',
                orientation='h',
                labels={'Reportes':'Reportes', 'Producto':'Producto'},
                color='Reportes',
                color_continuous_scale="Bluered"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("No hay datos para mostrar")

def render_trends_tab(filtered_df):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Eventos por Mes")
        if not filtered_df.empty:
            df_mensual = filtered_df.copy()
            df_mensual['Mes'] = df_mensual['Fecha_Reporte'].dt.to_period('M').dt.to_timestamp()
            df_mensual = df_mensual.groupby('Mes').size().reset_index(name='Reportes')
            
            fig = px.line(
                df_mensual, 
                x='Mes',
                y='Reportes',
                labels={'Reportes':'Reportes', 'Mes':'Fecha'},
                title="Tendencia Mensual de Reportes"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("No hay datos para mostrar")
    
    with col2:
        st.subheader("Duraci√≥n de Reacciones")
        if not filtered_df.empty:
            fig = px.box(
                filtered_df, 
                y="Duraci√≥n_Reacci√≥n", 
                x="Predicci√≥n",
                color="Predicci√≥n",
                points="all"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("No hay datos para mostrar")

def render_text_tab(filtered_df):
    st.subheader("An√°lisis de Texto")
    
    if not filtered_df.empty:
        st.write("**Palabras m√°s frecuentes en descripciones**")
        text = " ".join(filtered_df["Descripci√≥n"].tolist())
        
        # Create figure safely
        fig, ax = plt.subplots(figsize=(10, 5))
        
        if text.strip():
            try:
                wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
                ax.imshow(wordcloud, interpolation='bilinear')
            except:
                ax.text(0.5, 0.5, 'Error generando nube de palabras', 
                         horizontalalignment='center', 
                         verticalalignment='center',
                         fontsize=20)
        else:
            ax.text(0.5, 0.5, 'No hay texto disponible', 
                     horizontalalignment='center', 
                     verticalalignment='center',
                     fontsize=20)
        
        ax.axis("off")
        st.pyplot(fig)
        
        # TF-IDF
        st.write("**T√©rminos m√°s relevantes (TF-IDF)**")
        if text.strip():
            try:
                tfidf = TfidfVectorizer(max_features=10, stop_words=['de', 'la', 'el', 'en', 'y', 'que'])
                X = tfidf.fit_transform(filtered_df["Descripci√≥n"])
                tfidf_df = pd.DataFrame(X.toarray(), columns=tfidf.get_feature_names_out())
                st.bar_chart(tfidf_df.mean().sort_values(ascending=False))
            except:
                st.warning("Error en an√°lisis TF-IDF")
        else:
            st.warning("No hay texto suficiente para an√°lisis TF-IDF")
    else:
        st.warning("No hay datos para mostrar")

def render_map_tab(filtered_df):
    st.subheader("Distribuci√≥n Geogr√°fica")
    if not filtered_df.empty:
        country_counts = filtered_df["Pa√≠s"].value_counts().reset_index()
        country_counts.columns = ['Pa√≠s', 'Reportes']
        
        fig = px.choropleth(
            country_counts,
            locations="Pa√≠s",
            color="Reportes",
            hover_name="Pa√≠s",
            projection="natural earth",
            color_continuous_scale="Viridis",
            title="Reportes por Pa√≠s"
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("No hay datos para mostrar")

def render_visualizations(filtered_df):
    st.header("üìà An√°lisis Visual")
    tab1, tab2, tab3, tab4 = st.tabs(["Distribuci√≥n", "Tendencias", "Texto", "Mapa"])
    
    with tab1:
        render_distribution_tab(filtered_df)
    with tab2:
        render_trends_tab(filtered_df)
    with tab3:
        render_text_tab(filtered_df)
    with tab4:
        render_map_tab(filtered_df)
    
    st.markdown("---")

def render_sidebar(df):
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        num_records = st.slider("N√∫mero de reportes", 5, 50, 15)
        st.markdown("---")
        
        st.header("üîç Filtros")
        all_products = st.checkbox("Todos los productos", True, key="all_products")
        severidad_filtro = st.multiselect("Nivel de severidad:", options=["Leve", "Moderado", "Grave"])
        fecha_filtro = st.date_input("Reportes desde:", value=datetime.now() - timedelta(days=180))
        
        productos_filtro = []
        if not all_products:
            productos_filtro = st.multiselect(
                "Productos espec√≠ficos:", 
                options=df["Producto"].unique() if not df.empty else [],
                default=[]
            )
        
        st.markdown("---")
        st.info("Sophivigil v1.0 | Sistema de monitoreo de eventos adversos oft√°lmicos")
    
    return num_records, all_products, productos_filtro, severidad_filtro, fecha_filtro

def render_data_section(filtered_df):
    st.header("üìã Datos de Reportes")
    with st.expander("Ver datos completos", expanded=False):
        if not filtered_df.empty:
            # Convertir a string para evitar problemas de formato
            display_df = filtered_df.copy()
            date_cols = ["Inicio_Tratamiento", "Fin_Tratamiento", "Inicio_Reacci√≥n", 
                        "Fin_Reacci√≥n", "Fecha_Reporte"]
            for col in date_cols:
                if col in display_df.columns:
                    display_df[col] = display_df[col].dt.strftime('%Y-%m-%d')
            
            st.dataframe(display_df.style.background_gradient(
                subset=["Duraci√≥n_Reacci√≥n", "Duraci√≥n_Tratamiento"], 
                cmap="YlOrRd"
            ))
        else:
            st.warning("No hay datos disponibles con los filtros actuales")

def render_implementation_plan():
    st.header("üöÄ Pr√≥ximos Pasos")
    with st.expander("Plan de implementaci√≥n", expanded=False):
        st.markdown("""
        **Siguientes pasos para producci√≥n**:
        
        1. **Modelo Predictivo Real**  
           - Reemplazar modelo simulado con RandomForest/XGBoost entrenado
           - Incorporar embeddings cl√≠nicos (BioBERT)
        
        2. **Integraci√≥n de Datos**  
           - Conectar con base de datos PostgreSQL/MySQL
           - API para recepci√≥n de reportes en tiempo real
        
        3. **Sistema de Alertas**  
           - Notificaciones push a equipos m√©dicos
           - Integraci√≥n con Slack/Teams/Correo
        
        4. **Monitoreo Continuo**  
           - Dashboard de performance del modelo
           - Sistema de retraining autom√°tico
        
        5. **Funcionalidades Adicionales**  
           - B√∫squeda de casos similares
           - An√°lisis de se√±ales de seguridad
           - Integraci√≥n con sistemas de EHR
        """)
        
        st.progress(0.35, text="Estado actual del proyecto")

# ======================
# FUNCI√ìN PRINCIPAL
# ======================
def main():
    try:
        # T√≠tulo y separador
        st.title("üëÅÔ∏è Sophivigil ‚Äì Sistema de Farmacovigilancia Oft√°lmica")
        st.markdown("---")
        
        # Generar datos iniciales
        df = generate_adr_data(15)
        
        # Barra lateral
        num_records, all_products, productos_filtro, severidad_filtro, fecha_filtro = render_sidebar(df)
        
        # Regenerar datos si cambi√≥ el n√∫mero de registros
        if num_records != len(df):
            df = generate_adr_data(num_records)
        
        # Generar predicciones
        df = generate_predictions(df)
        
        # Aplicar filtros
        filtered_df = apply_filters(df, all_products, productos_filtro, severidad_filtro, fecha_filtro)
        
        # Secci√≥n de KPI
        render_kpi_section(df, filtered_df)
        
        # Visualizaciones
        render_visualizations(filtered_df)
        
        # Datos detallados
        render_data_section(filtered_df)
        
        # Plan de implementaci√≥n
        render_implementation_plan()
        
        # Footer
        st.markdown("---")
        st.caption("¬© 2023 Sophivigil - Sistema de Farmacovigilancia Oft√°lmica | Datos simulados con prop√≥sitos demostrativos")
    
    except Exception as e:
        st.error(f"**Error cr√≠tico en la aplicaci√≥n**: {str(e)}")
        st.error("Por favor recargue la p√°gina o contacte al equipo de soporte")
        st.stop()

# ======================
# EJECUCI√ìN PRINCIPAL
# ======================
if __name__ == "__main__":
    main()